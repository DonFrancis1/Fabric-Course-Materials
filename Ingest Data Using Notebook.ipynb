{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                " from pyspark.sql.types import *\n",
                "    \n",
                " # Create the schema for the table\n",
                " orderSchema = StructType([\n",
                "     StructField(\"SalesOrderNumber\", StringType()),\n",
                "     StructField(\"SalesOrderLineNumber\", IntegerType()),\n",
                "     StructField(\"OrderDate\", DateType()),\n",
                "     StructField(\"CustomerName\", StringType()),\n",
                "     StructField(\"Email\", StringType()),\n",
                "     StructField(\"Item\", StringType()),\n",
                "     StructField(\"Quantity\", IntegerType()),\n",
                "     StructField(\"UnitPrice\", FloatType()),\n",
                "     StructField(\"Tax\", FloatType())\n",
                "     ])\n",
                "    \n",
                " # Import all files from bronze folder of lakehouse\n",
                " df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(orderSchema).load(\"Files/bronze/*.csv\")\n",
                "    \n",
                " # Display the first 10 rows of the dataframe to preview your data\n",
                " display(df.head(10))"
            ],
            "metadata": {
                "azdata_cell_guid": "2e1233e5-3926-4727-b0f3-160f109facc0",
                "language": "sql"
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}